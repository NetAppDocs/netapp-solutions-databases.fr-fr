---
sidebar: sidebar 
permalink: automation/automation-ora-c-series-nfs.html 
keywords: Database, Oracle, Azure, ANF, Ansible, Automation 
summary: 'Cette solution fournit une vue d"ensemble et des détails pour le déploiement automatisé d"Oracle dans NetApp AFF C-Series en tant que stockage de base de données principal avec le protocole NFS.  La base de données Oracle se déploie en tant que base de données conteneur avec dNFS activé.' 
---
= TR-4992 : Déploiement Oracle simplifié et automatisé sur NetApp C-Series avec NFS
:hardbreaks:
:allow-uri-read: 
:nofooter: 
:icons: font
:linkattrs: 
:imagesdir: ../media/


Allen Cao, Niyaz Mohamed, NetApp

[role="lead"]
Cette solution fournit une vue d'ensemble et des détails pour le déploiement automatisé d'Oracle dans NetApp AFF C-Series en tant que stockage de base de données principal avec le protocole NFS.  La base de données Oracle se déploie en tant que base de données conteneur avec dNFS activé.



== But

NetApp AFF C-Series est un stockage flash de grande capacité qui rend le tout flash plus accessible et plus abordable pour le stockage unifié.  Ses performances sont suffisantes pour de nombreuses charges de travail de base de données Oracle de niveau 1 ou de niveau 2.  Alimentés par le logiciel de gestion de données NetApp ONTAP , les systèmes AFF C-Series offrent une efficacité de pointe, une flexibilité supérieure, des services de données de premier ordre et une intégration cloud pour vous aider à faire évoluer votre infrastructure informatique, à simplifier la gestion de vos données et à réduire les coûts de stockage et la consommation d'énergie.

Cette documentation démontre le déploiement simplifié des bases de données Oracle dans NetApp C-Series via des montages NFS à l'aide de l'automatisation Ansible.  La base de données Oracle se déploie dans une configuration de base de données conteneurisée (CDB) et de bases de données enfichables (PDB) avec le protocole Oracle dNFS activé pour améliorer les performances.  De plus, la solution fournit les meilleures pratiques en matière de configuration de réseau de stockage et de machine virtuelle de stockage (SVM) avec le protocole NFS sur les contrôleurs de stockage de la série C.  La solution comprend également des informations sur la sauvegarde, la restauration et le clonage rapides de bases de données Oracle avec l'outil d'interface utilisateur NetApp SnapCenter .

Cette solution répond aux cas d’utilisation suivants :

* Déploiement automatisé de bases de données de conteneurs Oracle sur les contrôleurs de stockage NetApp C-Series.
* Protection et clonage de base de données Oracle sur C-Series avec l'outil d'interface utilisateur SnapCenter .




== Public

Cette solution est destinée aux personnes suivantes :

* Un administrateur de base de données qui souhaite déployer Oracle sur NetApp C-Series.
* Un architecte de solutions de base de données qui souhaite tester les charges de travail Oracle sur NetApp C-Series.
* Un administrateur de stockage souhaitant déployer et gérer une base de données Oracle sur NetApp C-Series.
* Un propriétaire d'application qui souhaite mettre en place une base de données Oracle sur NetApp C-Series.




== Environnement de test et de validation de solutions

Les tests et la validation de cette solution ont été réalisés dans un environnement de laboratoire qui pourrait ne pas correspondre à l’environnement de déploiement final.  Voir la section<<Facteurs clés à prendre en compte lors du déploiement>> pour plus d'informations.



=== Architecture

image:automation-ora-c-series-nfs-architecture.png["Cette image fournit une image détaillée de la configuration de déploiement Oracle dans le cloud public AWS avec iSCSI et ASM."]



=== Composants matériels et logiciels

[cols="33%, 33%, 33%"]
|===


3+| *Matériel* 


| NetApp Série C C400 | ONTAP Version 9.13.1P3 | Deux étagères de disques / 24 disques d'une capacité de 278 Tio 


| VM pour serveur de base de données | 4 vCPU, 16 Go de RAM | Deux instances de machine virtuelle Linux pour un déploiement simultané 


| Machine virtuelle pour SnapCenter | 4 vCPU, 16 Go de RAM | Une instance de machine virtuelle Windows 


3+| *Logiciel* 


| RedHat Linux | RHEL Linux 8.6 (LVM) - x64 Gen2 | Abonnement RedHat déployé pour les tests 


| Windows Server | Centre de données x64 Gen2 2022 | Hébergement du serveur SnapCenter 


| Base de données Oracle | Version 19.18 | Patch RU appliqué p34765931_190000_Linux-x86-64.zip 


| Oracle OPatch | Version 12.2.0.1.36 | Dernier correctif p6880880_190000_Linux-x86-64.zip 


| Serveur SnapCenter | Version 5.0 | Déploiement de groupe de travail 


| Ouvrir le JDK | Version java-11-openjdk | Exigence du plug-in SnapCenter sur les machines virtuelles de base de données 


| NFS | Version 3.0 | Oracle dNFS activé 


| Ansible | noyau 2.16.2 | Python 3.6.8 
|===


=== Configuration de la base de données Oracle dans l'environnement de laboratoire

[cols="33%, 33%, 33%"]
|===


3+|  


| *Serveur* | *Base de données* | *Stockage de base de données* 


| ora_01 | NTAP1(NTAP1_PDB1,NTAP1_PDB2,NTAP1_PDB3) | /u01, /u02, /u03 Montages NFS sur volumes C400 


| ora_02 | NTAP2(NTAP2_PDB1,NTAP2_PDB2,NTAP2_PDB3) | /u01, /u02, /u03 Montages NFS sur volumes C400 
|===


=== Facteurs clés à prendre en compte lors du déploiement

* *Disposition de stockage de la base de données Oracle.*  Dans ce déploiement Oracle automatisé, nous provisionnons trois volumes de base de données pour chaque base de données afin d'héberger les binaires, les données et les journaux Oracle par défaut.  Les volumes sont montés sur le serveur Oracle DB en tant que /u01 - binaire, /u02 - données, /u03 - journaux via NFS.  Les fichiers de contrôle double sont configurés sur les points de montage /u02 et /u03 pour la redondance.
* *Déploiement de plusieurs serveurs de base de données.*  La solution d'automatisation peut déployer une base de données de conteneur Oracle sur plusieurs serveurs de base de données dans une seule exécution de playbook Ansible.  Quel que soit le nombre de serveurs de base de données, l’exécution du playbook reste la même.  Vous pouvez déployer plusieurs bases de données de conteneurs sur une seule instance de machine virtuelle en répétant le déploiement avec différents ID d'instance de base de données (SID Oracle).  Mais assurez-vous qu'il y a suffisamment de mémoire sur l'hôte pour prendre en charge les bases de données déployées.
* *Configuration dNFS.*  En utilisant dNFS (disponible depuis Oracle 11g), une base de données Oracle exécutée sur une machine virtuelle DB peut générer beaucoup plus d'E/S que le client NFS natif.  Le déploiement Oracle automatisé configure dNFS sur NFSv3 par défaut.
* *Équilibrage de charge sur la paire de contrôleurs C400.*  Placez les volumes de base de données Oracle sur les nœuds de contrôleur C400 de manière uniforme pour équilibrer la charge de travail.  DB1 sur le contrôleur 1, DB2 sur le contrôleur 2, et ainsi de suite.  Montez les volumes DB sur leur adresse lif locale.
* *Sauvegarde de la base de données.*  NetApp fournit une suite SnapCenter software pour la sauvegarde, la restauration et le clonage de bases de données avec une interface utilisateur conviviale.  NetApp recommande de mettre en œuvre un tel outil de gestion pour obtenir une sauvegarde instantanée rapide (moins d'une minute), une restauration rapide (quelques minutes) de la base de données et un clonage de la base de données.




== Déploiement de la solution

Les sections suivantes fournissent des procédures étape par étape pour le déploiement automatisé d'Oracle 19c et des informations sur la protection et le clonage de la base de données Oracle après le déploiement.



=== Prérequis pour le déploiement

[%collapsible%open]
====
Le déploiement nécessite les prérequis suivants.

. Une paire de contrôleurs de stockage NetApp C-Series est montée en rack, empilée et la dernière version du système d'exploitation ONTAP est installée et configurée.  Reportez-vous à ce guide de configuration si nécessaire : https://docs.netapp.com/us-en/ontap-systems/c400/install-detailed-guide.html#step-1-prepare-for-installation["Guide détaillé - AFF C400"^]
. Provisionnez deux machines virtuelles Linux comme serveurs de base de données Oracle.  Consultez le diagramme d’architecture dans la section précédente pour plus de détails sur la configuration de l’environnement.
. Provisionnez un serveur Windows pour exécuter l’outil d’interface utilisateur NetApp SnapCenter avec la dernière version.  Consultez le lien suivant pour plus de détails :link:https://docs.netapp.com/us-en/snapcenter/install/task_install_the_snapcenter_server_using_the_install_wizard.html["Installer le serveur SnapCenter"^]
. Provisionnez une machine virtuelle Linux en tant que nœud de contrôleur Ansible avec la dernière version d'Ansible et de Git installée.  Consultez le lien suivant pour plus de détails :link:https://docs.netapp.com/us-en/netapp-solutions-dataops/automation/getting-started.html["Premiers pas avec l'automatisation des solutions NetApp ^"^] dans la section -
`Setup the Ansible Control Node for CLI deployments on RHEL / CentOS` ou
`Setup the Ansible Control Node for CLI deployments on Ubuntu / Debian` .
+
Activez l'authentification par clé publique/privée SSH entre le contrôleur Ansible et les machines virtuelles de base de données.

. À partir du répertoire de base de l’utilisateur administrateur du contrôleur Ansible, clonez une copie de la boîte à outils d’automatisation de déploiement NetApp Oracle pour NFS.
+
[source, cli]
----
git clone https://bitbucket.ngage.netapp.com/scm/ns-bb/na_oracle_deploy_nfs.git
----
. Étape suivant les fichiers d'installation d'Oracle 19c sur le répertoire DB VM /tmp/archive avec l'autorisation 777.
+
....
installer_archives:
  - "LINUX.X64_193000_db_home.zip"
  - "p34765931_190000_Linux-x86-64.zip"
  - "p6880880_190000_Linux-x86-64.zip"
....


====


=== Configurer la mise en réseau et SVM sur C-Series pour Oracle

[%collapsible%open]
====
Cette section du guide de déploiement présente les meilleures pratiques pour configurer une machine virtuelle de mise en réseau et de stockage (SVM) sur un contrôleur de la série C pour la charge de travail Oracle avec le protocole NFS à l'aide de l'interface utilisateur d' ONTAP System Manager.

. Connectez-vous à ONTAP System Manager pour vérifier qu'après l'installation initiale du cluster ONTAP , les domaines de diffusion ont été configurés avec des ports Ethernet correctement attribués à chaque domaine.  En règle générale, il doit y avoir un domaine de diffusion pour le cluster, un domaine de diffusion pour la gestion et un domaine de diffusion pour la charge de travail telle que les données.
+
image:automation-ora-c-series-nfs-net-001.png["Cette image fournit une capture d'écran pour la configuration du contrôleur de la série C"]

. Depuis RÉSEAU - Ports Ethernet, cliquez sur `Link Aggregate Group` pour créer un port de groupe d'agrégation de liens LACP a0a, qui fournit un équilibre de charge et un basculement entre les ports membres du port de groupe d'agrégation.  Il existe 4 ports de données - e0e, e0f, e0g, e0h - disponibles sur les contrôleurs C400.
+
image:automation-ora-c-series-nfs-net-002.png["Cette image fournit une capture d'écran pour la configuration du contrôleur de la série C"]

. Sélectionnez les ports Ethernet dans le groupe, `LACP` pour le mode, et `Port` pour la répartition de la charge.
+
image:automation-ora-c-series-nfs-net-003.png["Cette image fournit une capture d'écran pour la configuration du contrôleur de la série C"]

. Valider le port LACP a0a créé et le domaine de diffusion `Data` fonctionne désormais sur le port LACP.
+
image:automation-ora-c-series-nfs-net-004.png["Cette image fournit une capture d'écran pour la configuration du contrôleur de la série C"] image:automation-ora-c-series-nfs-net-005.png["Cette image fournit une capture d'écran pour la configuration du contrôleur de la série C"]

. Depuis `Ethernet Ports` , cliquez `VLAN` pour ajouter un VLAN sur chaque nœud de contrôleur pour la charge de travail Oracle sur le protocole NFS.
+
image:automation-ora-c-series-nfs-net-006.png["Cette image fournit une capture d'écran pour la configuration du contrôleur de la série C"] image:automation-ora-c-series-nfs-net-007.png["Cette image fournit une capture d'écran pour la configuration du contrôleur de la série C"] image:automation-ora-c-series-nfs-net-008.png["Cette image fournit une capture d'écran pour la configuration du contrôleur de la série C"]

. Connectez-vous aux contrôleurs de la série C à partir de l'adresse IP de gestion du cluster via SSH pour valider que les groupes de basculement réseau sont correctement configurés.  ONTAP crée et gère automatiquement les groupes de basculement.
+
....

HCG-NetApp-C400-E9U9::> net int failover-groups show
  (network interface failover-groups show)
                                  Failover
Vserver          Group            Targets
---------------- ---------------- --------------------------------------------
Cluster
                 Cluster
                                  HCG-NetApp-C400-E9U9a:e0c,
                                  HCG-NetApp-C400-E9U9a:e0d,
                                  HCG-NetApp-C400-E9U9b:e0c,
                                  HCG-NetApp-C400-E9U9b:e0d
HCG-NetApp-C400-E9U9
                 Data
                                  HCG-NetApp-C400-E9U9a:a0a,
                                  HCG-NetApp-C400-E9U9a:a0a-3277,
                                  HCG-NetApp-C400-E9U9b:a0a,
                                  HCG-NetApp-C400-E9U9b:a0a-3277
                 Mgmt
                                  HCG-NetApp-C400-E9U9a:e0M,
                                  HCG-NetApp-C400-E9U9b:e0M
3 entries were displayed.

....
. Depuis `STORAGE - Storage VMs` , cliquez sur +Ajouter pour créer un SVM pour Oracle.
+
image:automation-ora-c-series-nfs-svm-001.png["Cette image fournit une capture d'écran pour la configuration du contrôleur de la série C"]

. Nommez votre Oracle SVM, vérifiez `Enable NFS` et `Allow NFS client access` .
+
image:automation-ora-c-series-nfs-svm-002.png["Cette image fournit une capture d'écran pour la configuration du contrôleur de la série C"]

. Ajouter une politique d'exportation NFS `Default` règles.
+
image:automation-ora-c-series-nfs-svm-003.png["Cette image fournit une capture d'écran pour la configuration du contrôleur de la série C"]

. Dans `NETWORK INTERFACE` , remplissez l'adresse IP sur chaque nœud pour les adresses NFS lif.
+
image:automation-ora-c-series-nfs-svm-004.png["Cette image fournit une capture d'écran pour la configuration du contrôleur de la série C"]

. Validez que SVM pour Oracle est opérationnel et que le statut NFS lifs est actif.
+
image:automation-ora-c-series-nfs-svm-005.png["Cette image fournit une capture d'écran pour la configuration du contrôleur de la série C"] image:automation-ora-c-series-nfs-svm-006.png["Cette image fournit une capture d'écran pour la configuration du contrôleur de la série C"]

. Depuis `STORAGE-Volumes` onglet pour ajouter des volumes NFS pour la base de données Oracle.
+
image:automation-ora-c-series-nfs-vol-001.png["Cette image fournit une capture d'écran pour la configuration du contrôleur de la série C"]

. Nommez votre volume, attribuez-lui une capacité et un niveau de performance.
+
image:automation-ora-c-series-nfs-vol-002.png["Cette image fournit une capture d'écran pour la configuration du contrôleur de la série C"]

. Dans `Access Permission` , choisissez la politique par défaut créée à l’étape précédente.  Décocher `Enable Snapshot Copies` car nous préférons utiliser SnapCenter pour créer des instantanés cohérents avec les applications.
+
image:automation-ora-c-series-nfs-vol-003.png["Cette image fournit une capture d'écran pour la configuration du contrôleur de la série C"]

. Créez trois volumes de base de données pour chaque serveur de base de données : server_name_u01 - binaire, server_name_u02 - données, server_name_u03 - journaux.
+
image:automation-ora-c-series-nfs-vol-004.png["Cette image fournit une capture d'écran pour la configuration du contrôleur de la série C"]

+

NOTE: La convention de nommage du volume de base de données doit suivre strictement le format indiqué ci-dessus pour garantir que l'automatisation fonctionne correctement.



Ceci termine la configuration du contrôleur de la série C pour Oracle.

====


=== Fichiers de paramètres d'automatisation

[%collapsible%open]
====
Le playbook Ansible exécute les tâches d'installation et de configuration de la base de données avec des paramètres prédéfinis.  Pour cette solution d’automatisation Oracle, il existe trois fichiers de paramètres définis par l’utilisateur qui nécessitent une saisie de l’utilisateur avant l’exécution du playbook.

* hôtes - définissez les cibles sur lesquelles le playbook d'automatisation s'exécute.
* vars/vars.yml - le fichier de variables globales qui définit les variables qui s'appliquent à toutes les cibles.
* host_vars/host_name.yml - le fichier de variables locales qui définit les variables qui s'appliquent uniquement à une cible nommée.  Dans notre cas d’utilisation, il s’agit des serveurs de base de données Oracle.


En plus de ces fichiers de variables définis par l'utilisateur, il existe plusieurs fichiers de variables par défaut qui contiennent des paramètres par défaut qui ne nécessitent aucune modification, sauf si nécessaire.  Les sections suivantes montrent comment configurer les fichiers de variables définis par l'utilisateur.

====


=== Configuration des fichiers de paramètres

[%collapsible%open]
====
. Cible Ansible `hosts` configuration du fichier :
+
[source, shell]
----
# Enter Oracle servers names to be deployed one by one, follow by each Oracle server public IP address, and ssh private key of admin user for the server.
[oracle]
ora_01 ansible_host=10.61.180.21 ansible_ssh_private_key_file=ora_01.pem
ora_02 ansible_host=10.61.180.23 ansible_ssh_private_key_file=ora_02.pem

----


. Mondial `vars/vars.yml` configuration du fichier
+
[source, shell]
----
######################################################################
###### Oracle 19c deployment user configuration variables       ######
###### Consolidate all variables from ONTAP, linux and oracle   ######
######################################################################

###########################################
### ONTAP env specific config variables ###
###########################################

# Prerequisite to create three volumes in NetApp ONTAP storage from System Manager or cloud dashboard with following naming convention:
# db_hostname_u01 - Oracle binary
# db_hostname_u02 - Oracle data
# db_hostname_u03 - Oracle redo
# It is important to strictly follow the name convention or the automation will fail.


###########################################
### Linux env specific config variables ###
###########################################

redhat_sub_username: XXXXXXXX
redhat_sub_password: XXXXXXXX


####################################################
### DB env specific install and config variables ###
####################################################

# Database domain name
db_domain: solutions.netapp.com

# Set initial password for all required Oracle passwords. Change them after installation.
initial_pwd_all: XXXXXXXX

----


. Serveur de base de données local `host_vars/host_name.yml` configuration telle que ora_01.yml, ora_02.yml ...
+
[source, shell]
----
# User configurable Oracle host specific parameters

# Enter container database SID. By default, a container DB is created with 3 PDBs within the CDB
oracle_sid: NTAP1

# Enter database shared memory size or SGA. CDB is created with SGA at 75% of memory_limit, MB. The grand total of SGA should not exceed 75% available RAM on node.
memory_limit: 8192

# Local NFS lif ip address to access database volumes
nfs_lif: 172.30.136.68

----


====


=== Exécution du manuel de jeu

[%collapsible%open]
====
Il existe au total cinq playbooks dans la boîte à outils d’automatisation.  Chacun exécute des blocs de tâches différents et sert des objectifs différents.

....
0-all_playbook.yml - execute playbooks from 1-4 in one playbook run.
1-ansible_requirements.yml - set up Ansible controller with required libs and collections.
2-linux_config.yml - execute Linux kernel configuration on Oracle DB servers.
4-oracle_config.yml - install and configure Oracle on DB servers and create a container database.
5-destroy.yml - optional to undo the environment to dismantle all.
....
Il existe trois options pour exécuter les playbooks avec les commandes suivantes.

. Exécutez tous les playbooks de déploiement en une seule exécution combinée.
+
[source, cli]
----
ansible-playbook -i hosts 0-all_playbook.yml -u admin -e @vars/vars.yml
----
. Exécutez les playbooks un par un avec la séquence de nombres de 1 à 4.
+
[source, cli]]
----
ansible-playbook -i hosts 1-ansible_requirements.yml -u admin -e @vars/vars.yml
----
+
[source, cli]
----
ansible-playbook -i hosts 2-linux_config.yml -u admin -e @vars/vars.yml
----
+
[source, cli]
----
ansible-playbook -i hosts 4-oracle_config.yml -u admin -e @vars/vars.yml
----
. Exécutez 0-all_playbook.yml avec une balise.
+
[source, cli]
----
ansible-playbook -i hosts 0-all_playbook.yml -u admin -e @vars/vars.yml -t ansible_requirements
----
+
[source, cli]
----
ansible-playbook -i hosts 0-all_playbook.yml -u admin -e @vars/vars.yml -t linux_config
----
+
[source, cli]
----
ansible-playbook -i hosts 0-all_playbook.yml -u admin -e @vars/vars.yml -t oracle_config
----
. Défaire l'environnement
+
[source, cli]
----
ansible-playbook -i hosts 5-destroy.yml -u admin -e @vars/vars.yml
----


====


=== Validation post-exécution

[%collapsible%open]
====
Après l'exécution du playbook, connectez-vous à la machine virtuelle du serveur Oracle DB pour valider qu'Oracle est installé et configuré et qu'une base de données de conteneur est créée avec succès.  Voici un exemple de validation de base de données Oracle sur la machine virtuelle DB ora_01 ou ora_02.

. Valider les montages NFS
+
....

[admin@ora_01 ~]$ cat /etc/fstab

#
# /etc/fstab
# Created by anaconda on Wed Oct 18 19:43:31 2023
#
# Accessible filesystems, by reference, are maintained under '/dev/disk/'.
# See man pages fstab(5), findfs(8), mount(8) and/or blkid(8) for more info.
#
# After editing this file, run 'systemctl daemon-reload' to update systemd
# units generated from this file.
#
/dev/mapper/rhel-root   /                       xfs     defaults        0 0
UUID=aff942c4-b224-4b62-807d-6a5c22f7b623 /boot                   xfs     defaults        0 0
/dev/mapper/rhel-swap   none                    swap    defaults        0 0
/root/swapfile swap swap defaults 0 0
172.21.21.100:/ora_01_u01 /u01 nfs rw,bg,hard,vers=3,proto=tcp,timeo=600,rsize=65536,wsize=65536 0 0
172.21.21.100:/ora_01_u02 /u02 nfs rw,bg,hard,vers=3,proto=tcp,timeo=600,rsize=65536,wsize=65536 0 0
172.21.21.100:/ora_01_u03 /u03 nfs rw,bg,hard,vers=3,proto=tcp,timeo=600,rsize=65536,wsize=65536 0 0


[admin@ora_01 tmp]$ df -h
Filesystem                 Size  Used Avail Use% Mounted on
devtmpfs                   7.7G     0  7.7G   0% /dev
tmpfs                      7.8G     0  7.8G   0% /dev/shm
tmpfs                      7.8G   18M  7.8G   1% /run
tmpfs                      7.8G     0  7.8G   0% /sys/fs/cgroup
/dev/mapper/rhel-root       44G   28G   17G  62% /
/dev/sda1                 1014M  258M  757M  26% /boot
tmpfs                      1.6G   12K  1.6G   1% /run/user/42
tmpfs                      1.6G  4.0K  1.6G   1% /run/user/1000
172.21.21.100:/ora_01_u01   50G  8.7G   42G  18% /u01
172.21.21.100:/ora_01_u02  200G  384K  200G   1% /u02
172.21.21.100:/ora_01_u03  100G  320K  100G   1% /u03

[admin@ora_02 ~]$ df -h
Filesystem                 Size  Used Avail Use% Mounted on
devtmpfs                   7.7G     0  7.7G   0% /dev
tmpfs                      7.8G     0  7.8G   0% /dev/shm
tmpfs                      7.8G   18M  7.8G   1% /run
tmpfs                      7.8G     0  7.8G   0% /sys/fs/cgroup
/dev/mapper/rhel-root       44G   28G   17G  63% /
/dev/sda1                 1014M  258M  757M  26% /boot
tmpfs                      1.6G   12K  1.6G   1% /run/user/42
tmpfs                      1.6G  4.0K  1.6G   1% /run/user/1000
172.21.21.101:/ora_02_u01   50G  7.8G   43G  16% /u01
172.21.21.101:/ora_02_u02  200G  320K  200G   1% /u02
172.21.21.101:/ora_02_u03  100G  320K  100G   1% /u03

....
. Valider l'écouteur Oracle
+
....

[admin@ora_02 ~]$ sudo su
[root@ora_02 admin]# su - oracle
[oracle@ora_02 ~]$ lsnrctl status listener.ntap2

LSNRCTL for Linux: Version 19.0.0.0.0 - Production on 29-MAY-2024 12:13:30

Copyright (c) 1991, 2022, Oracle.  All rights reserved.

Connecting to (DESCRIPTION=(ADDRESS=(PROTOCOL=TCP)(HOST=ora_02.cie.netapp.com)(PORT=1521)))
STATUS of the LISTENER
------------------------
Alias                     LISTENER.NTAP2
Version                   TNSLSNR for Linux: Version 19.0.0.0.0 - Production
Start Date                23-MAY-2024 16:13:03
Uptime                    5 days 20 hr. 0 min. 26 sec
Trace Level               off
Security                  ON: Local OS Authentication
SNMP                      OFF
Listener Parameter File   /u01/app/oracle/product/19.0.0/NTAP2/network/admin/listener.ora
Listener Log File         /u01/app/oracle/diag/tnslsnr/ora_02/listener.ntap2/alert/log.xml
Listening Endpoints Summary...
  (DESCRIPTION=(ADDRESS=(PROTOCOL=tcp)(HOST=ora_02.cie.netapp.com)(PORT=1521)))
  (DESCRIPTION=(ADDRESS=(PROTOCOL=ipc)(KEY=EXTPROC1521)))
  (DESCRIPTION=(ADDRESS=(PROTOCOL=tcps)(HOST=ora_02.cie.netapp.com)(PORT=5500))(Security=(my_wallet_directory=/u01/app/oracle/product/19.0.0/NTAP2/admin/NTAP2/xdb_wallet))(Presentation=HTTP)(Session=RAW))
Services Summary...
Service "192551f1d7e65fc3e06308b43d0a63ae.solutions.netapp.com" has 1 instance(s).
  Instance "NTAP2", status READY, has 1 handler(s) for this service...
Service "1925529a43396002e06308b43d0a2d5a.solutions.netapp.com" has 1 instance(s).
  Instance "NTAP2", status READY, has 1 handler(s) for this service...
Service "1925530776b76049e06308b43d0a49c3.solutions.netapp.com" has 1 instance(s).
  Instance "NTAP2", status READY, has 1 handler(s) for this service...
Service "NTAP2.solutions.netapp.com" has 1 instance(s).
  Instance "NTAP2", status READY, has 1 handler(s) for this service...
Service "NTAP2XDB.solutions.netapp.com" has 1 instance(s).
  Instance "NTAP2", status READY, has 1 handler(s) for this service...
Service "ntap2_pdb1.solutions.netapp.com" has 1 instance(s).
  Instance "NTAP2", status READY, has 1 handler(s) for this service...
Service "ntap2_pdb2.solutions.netapp.com" has 1 instance(s).
  Instance "NTAP2", status READY, has 1 handler(s) for this service...
Service "ntap2_pdb3.solutions.netapp.com" has 1 instance(s).
  Instance "NTAP2", status READY, has 1 handler(s) for this service...
The command completed successfully
[oracle@ora_02 ~]$

....
. Valider la base de données Oracle et dNFS
+
....

[oracle@ora-01 ~]$ cat /etc/oratab
#
# This file is used by ORACLE utilities.  It is created by root.sh
# and updated by either Database Configuration Assistant while creating
# a database or ASM Configuration Assistant while creating ASM instance.

# A colon, ':', is used as the field terminator.  A new line terminates
# the entry.  Lines beginning with a pound sign, '#', are comments.
#
# Entries are of the form:
#   $ORACLE_SID:$ORACLE_HOME:<N|Y>:
#
# The first and second fields are the system identifier and home
# directory of the database respectively.  The third field indicates
# to the dbstart utility that the database should , "Y", or should not,
# "N", be brought up at system boot time.
#
# Multiple entries with the same $ORACLE_SID are not allowed.
#
#
NTAP1:/u01/app/oracle/product/19.0.0/NTAP1:Y


[oracle@ora-01 ~]$ sqlplus / as sysdba

SQL*Plus: Release 19.0.0.0.0 - Production on Thu Feb 1 16:37:51 2024
Version 19.18.0.0.0

Copyright (c) 1982, 2022, Oracle.  All rights reserved.


Connected to:
Oracle Database 19c Enterprise Edition Release 19.0.0.0.0 - Production
Version 19.18.0.0.0

SQL> select name, open_mode, log_mode from v$database;

NAME      OPEN_MODE            LOG_MODE
--------- -------------------- ------------
NTAP1     READ WRITE           ARCHIVELOG

SQL> show pdbs

    CON_ID CON_NAME                       OPEN MODE  RESTRICTED
---------- ------------------------------ ---------- ----------
         2 PDB$SEED                       READ ONLY  NO
         3 NTAP1_PDB1                     READ WRITE NO
         4 NTAP1_PDB2                     READ WRITE NO
         5 NTAP1_PDB3                     READ WRITE NO
SQL> select name from v$datafile;

NAME
--------------------------------------------------------------------------------
/u02/oradata/NTAP1/system01.dbf
/u02/oradata/NTAP1/sysaux01.dbf
/u02/oradata/NTAP1/undotbs01.dbf
/u02/oradata/NTAP1/pdbseed/system01.dbf
/u02/oradata/NTAP1/pdbseed/sysaux01.dbf
/u02/oradata/NTAP1/users01.dbf
/u02/oradata/NTAP1/pdbseed/undotbs01.dbf
/u02/oradata/NTAP1/NTAP1_pdb1/system01.dbf
/u02/oradata/NTAP1/NTAP1_pdb1/sysaux01.dbf
/u02/oradata/NTAP1/NTAP1_pdb1/undotbs01.dbf
/u02/oradata/NTAP1/NTAP1_pdb1/users01.dbf

NAME
--------------------------------------------------------------------------------
/u02/oradata/NTAP1/NTAP1_pdb2/system01.dbf
/u02/oradata/NTAP1/NTAP1_pdb2/sysaux01.dbf
/u02/oradata/NTAP1/NTAP1_pdb2/undotbs01.dbf
/u02/oradata/NTAP1/NTAP1_pdb2/users01.dbf
/u02/oradata/NTAP1/NTAP1_pdb3/system01.dbf
/u02/oradata/NTAP1/NTAP1_pdb3/sysaux01.dbf
/u02/oradata/NTAP1/NTAP1_pdb3/undotbs01.dbf
/u02/oradata/NTAP1/NTAP1_pdb3/users01.dbf

19 rows selected.

SQL> select name from v$controlfile;

NAME
--------------------------------------------------------------------------------
/u02/oradata/NTAP1/control01.ctl
/u03/orareco/NTAP1/control02.ctl

SQL> select member from v$logfile;

MEMBER
--------------------------------------------------------------------------------
/u03/orareco/NTAP1/onlinelog/redo03.log
/u03/orareco/NTAP1/onlinelog/redo02.log
/u03/orareco/NTAP1/onlinelog/redo01.log

SQL> select svrname, dirname from v$dnfs_servers;

SVRNAME
--------------------------------------------------------------------------------
DIRNAME
--------------------------------------------------------------------------------
172.21.21.100
/ora_01_u02

172.21.21.100
/ora_01_u03

172.21.21.100
/ora_01_u01


....
. Connectez-vous à Oracle Enterprise Manager Express pour valider la base de données.
+
image:automation-ora-c-series-nfs-em-001.png["Cette image fournit l'écran de connexion pour Oracle Enterprise Manager Express"] image:automation-ora-c-series-nfs-em-002.png["Cette image fournit une vue de la base de données du conteneur à partir d'Oracle Enterprise Manager Express"] image:automation-ora-c-series-nfs-em-003.png["Cette image fournit une vue de la base de données du conteneur à partir d'Oracle Enterprise Manager Express"]



====


=== Sauvegarde, restauration et clonage Oracle avec SnapCenter

[%collapsible%open]
====
NetApp recommande l'outil d'interface utilisateur SnapCenter pour gérer la base de données Oracle déployée dans C-Series.  Se référer à TR-4979link:../oracle/aws-ora-fsx-vmc-guestmount.html#oracle-backup-restore-and-clone-with-snapcenter["Oracle simplifié et autogéré dans VMware Cloud sur AWS avec FSx ONTAP monté en invité"^] section `Oracle backup, restore, and clone with SnapCenter` pour plus de détails sur la configuration de SnapCenter et l'exécution des flux de travail de sauvegarde, de restauration et de clonage de la base de données.

====


== Où trouver des informations supplémentaires

Pour en savoir plus sur les informations décrites dans ce document, consultez les documents et/ou sites Web suivants :

* link:https://www.netapp.com/pdf.html?item=/media/81583-da-4240-aff-c-series.pdf["NetApp AFF Série C"^]
* link:https://docs.oracle.com/en/database/oracle/oracle-database/19/ladbi/deploying-dnfs.html#GUID-D06079DB-8C71-4F68-A1E3-A75D7D96DCE2["Déploiement d'Oracle Direct NFS"^]

